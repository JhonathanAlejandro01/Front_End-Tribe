{"ast":null,"code":"//Class Video_Tracking\nclass VideoTracking {\n  constructor(model_config_number, config_prediction_number, type_device_number, device_id_str = 'null') {\n    this.model_architeture_options = [{\n      architecture: \"MobileNetV1\",\n      outputStride: 16,\n      multiplier: 0.5,\n      quantBytes: 2\n    }, {\n      architecture: 'MobileNetV1',\n      outputStride: 16,\n      multiplier: 0.75,\n      quantBytes: 2\n    }, {\n      architecture: 'MobileNetV1',\n      outputStride: 16,\n      multiplier: 0.75,\n      quantBytes: 2\n    }, {\n      architecture: 'MobileNetV1',\n      outputStride: 8,\n      multiplier: 1,\n      quantBytes: 2\n    }, {\n      architecture: 'ResNet50',\n      outputStride: 16,\n      quantBytes: 2\n    }];\n    this.effect_config_precission = [{\n      flipHorizontal: false,\n      internalResolution: 'low',\n      segmentationThreshold: 0.7\n    }, {\n      flipHorizontal: false,\n      internalResolution: 'medium',\n      segmentationThreshold: 0.7\n    }, {\n      flipHorizontal: false,\n      internalResolution: 'high',\n      segmentationThreshold: 0.7\n    }, {\n      flipHorizontal: false,\n      internalResolution: 'ultra',\n      segmentationThreshold: 0.7\n    }];\n    this.type_of_device = [{\n      audio: false,\n      video: {\n        facingMode: \"user\",\n        width: 960,\n        height: 540\n      }\n    }, {\n      audio: false,\n      video: {\n        facingMode: {\n          exact: \"environment\"\n        },\n        width: 960,\n        height: 540\n      }\n    }, {\n      audio: false,\n      video: {\n        deviceId: device_id_str,\n        width: 960,\n        height: 540\n      }\n    }, {\n      audio: false,\n      video: {\n        width: 960,\n        height: 540\n      }\n    }];\n    this.selection_model_option = this.model_architeture_options[model_config_number];\n    this.selection_effect_option = this.effect_config_precission[config_prediction_number];\n    this.selection_type_device = this.type_of_device[type_device_number];\n    this.model = this._load_model(this.selection_model_option);\n    /*Promise Containtng Model*/\n\n    this.videoStream = this.load_Video_stream(this.selection_type_device);\n    /*Promise Containing Video MediaStream*/\n\n    this.canvasElemenet = this.createCanvas(960, 540);\n    this.VideoElement = this.createVideo(960, 540);\n    /*Video Element*/\n    //this.canvasElement = this.createCanvas(this.width, this.height);/*Create canvas to Write to setting some dimensions*/\n\n    /*podemos usar esto*/\n\n    this.predictionModel = new Prediction(this.model, this.videoStream, this.canvasElemenet);\n  }\n\n  createCanvas(width, height) {\n    const canvas = document.createElement('canvas');\n    canvas.setAttribute('width', width);\n    canvas.setAttribute('height', height);\n    return canvas;\n  }\n\n  static addVideo(HTMLelement, videoElement) {\n    HTMLelement.appendChild(videoElement);\n  }\n\n  _load_model(model_config) {\n    return bodyPix.load(model_config);\n  }\n\n  async load_Video_stream(config_constrains) {\n    const stream = await navigator.mediaDevices.getUserMedia(config_constrains);\n    /*MediaStream Video*/\n\n    this.deviceId = stream.getVideoTracks()[0].getCapabilities().deviceId;\n    this.frameRate = stream.getVideoTracks()[0].getCapabilities().frameRate;\n    this.height = stream.getVideoTracks()[0].getCapabilities().height;\n    this.width = stream.getVideoTracks()[0].getCapabilities().width;\n    this.VideoElement.srcObject = stream;\n    /*SetVideo Stream Source*/\n\n    /*MediaStream Video*/\n\n    this.video_stream = stream;\n    return this.PromiseCreator();\n  }\n\n  createVideo(width, height) {\n    /*Create Video de donde sacaramos la informacion para hacer la prediccion y posteriormente dibujar el canvas*/\n    const video = document.createElement('video');\n    video.setAttribute('autoplay', 'false');\n    video.setAttribute('width', width);\n    video.setAttribute('height', height); //video.setAttribute('playsinline', 'false');\n    //video.setAttribute('controls', 'false');\n    //video.style.visibility = 'visible';\n\n    video.style.display = 'none';\n    return video;\n  }\n\n  PromiseCreator() {\n    /* Return Promise VideoElement when all data is loaded and ready  with certains dimensions*/\n    return new Promise((resolve, reject) => {\n      this.VideoElement.onloadedmetadata = () => {\n        this.VideoElement.width = this.VideoElement.videoWidth;\n        this.VideoElement.height = this.VideoElement.videoHeight;\n        resolve(this.VideoElement);\n      };\n    });\n  }\n\n} //Class Prediction\n\n\nclass Prediction {\n  /*config = flipHorizontal: true, internalResolution: 'high', segmentationThreshold: 0.7*/\n\n  /*config (additional for MultiPerson) = maxDetections: 10,scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10*/\n\n  /* type_prediciton = String 'Person', 'MultiPerson'*/\n  constructor(loaded_model, videoMediaStream, canvasElemenet) {\n    this.loaded_model = loaded_model;\n    /*Promise of Model*/\n\n    this.videoMediaStream = videoMediaStream;\n    this.stop = false;\n    /*Stop Animation Loop*/\n\n    this.canvasElement = canvasElemenet;\n  }\n\n  async make_prediction_load() {\n    /* Returns unit8Campled for every pixel in the Ho*Wo Element array 0: Backgrounnd : 1:Person*/\n\n    /*type_prediciton 1 --> Person, 2 --> MultiPerson, 3 --> BodyParts Prediciton/\n    /*HTMLVideoElement --> ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement*/\n    if (typeof this.loaded_video === 'undefined') {\n      /* Load one time video MediaStream if was not loaded yet*/\n      this.loaded_video = await this.videoMediaStream;\n      this.model_prediction = await this.loaded_model;\n      /*cargando el model*/\n\n      /*add video to HTML*/\n\n      this.height = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().height;\n      this.width = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().width;\n      VideoTracking.addVideo(document.querySelector('body'), this.loaded_video); // No es necesario anadir el HTML.... xd\n    }\n  }\n\n  async stream_properties_mediaStream() {\n    await this.make_prediction_load();\n    /*if video is no loaded yet*/\n\n    this.deviceId = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().deviceId;\n    this.frameRate = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().frameRate;\n    this.height = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().height;\n    this.width = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().width;\n    return [this.deviceId, this.frameRate, this.height, this.width];\n  }\n\n  canvas_mediStream() {\n    const stream = this.canvasElement.captureStream(24);\n    /*Adding stream to video for testing*/\n\n    const test_video = document.querySelector('#testing');\n    /*testing canvas_mediStream*/\n\n    test_video.setAttribute('width', 960);\n    test_video.setAttribute('height', 540);\n    test_video.setAttribute('autoplay', 'true');\n\n    test_video.onloadedmetadata = () => {\n      test_video.width = test_video.videoWidth;\n      test_video.height = test_video.videoHeight;\n    };\n\n    test_video.style.visibility = 'visible';\n    test_video.srcObject = stream;\n    this.canvas_stream = stream;\n    return stream;\n  }\n\n  async virtualBackground_(prediction, canvasElement, videoElement, config) {\n    const {\n      URL\n    } = config; //new canvas\n\n    const canvas = canvasElement; //cremaos un blank array para llenarlo\n\n    const newImg = canvas.getContext('2d').createImageData(960, 540); //create blank new ImageData\n\n    const newImgData = newImg.data; //prediction\n\n    const {\n      data: map\n    } = prediction;\n    const pixelLength = map.length; //Video Data\n\n    const {\n      data: videoData\n    } = await this.videoImageData(960, 540, videoElement); //imageData\n\n    const {\n      data: imgData\n    } = await this.getImageData(960, 540, URL); //es los pixels de no persona dibujar La imagen en si\n\n    for (let i = 0; i < pixelLength; i++) {\n      //los pixels de la imagen si es no es persona\n      const [r, g, b, a] = [imgData[i * 4], imgData[i * 4 + 1], imgData[i * 4 + 2], imgData[i * 4 + 3]]; //revisamos que sea 1 persona , 0 otra cosa\n\n      [newImgData[i * 4], newImgData[i * 4 + 1], newImgData[i * 4 + 2], newImgData[i * 4 + 3]] = !map[i] ? [r, g, b, 255] : [videoData[i * 4], videoData[i * 4 + 1], videoData[i * 4 + 2], 0];\n    }\n\n    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n    const {\n      backgroundBlurAmount,\n      edgeBlurAmount,\n      flipHorizontal\n    } = config;\n    bodyPix.drawMask(canvas, videoElement, newImg, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n  }\n\n  async videoImageData(width, height, videoElement) {\n    /*Create Canvas*/\n    const canvas = document.createElement('canvas');\n    canvas.setAttribute('width', width);\n    canvas.setAttribute('height', height);\n    /*Write data To image*/\n\n    const context = canvas.getContext('2d');\n    const img = videoElement;\n    context.drawImage(img, 0, 0);\n    var theData = context.getImageData(0, 0, width, height);\n    return theData;\n  }\n\n  async getImageData(width, height, URL) {\n    //create Image object\n    const canvas = document.createElement('canvas');\n    const ctx = canvas.getContext('2d');\n    canvas.width = width;\n    canvas.height = height;\n    /*create new image*/\n\n    const img = new Image();\n    img.crossOrigin = '';\n    await new Promise(r => img.onload = r, img.src = URL); //resize image to canvas\n\n    ctx.imageSmoothingEnabled = true;\n    ctx.imageSmoothingQuality = 'high';\n    ctx.drawImage(img, 0, 0, img.width, img.height, //source rectangle\n    0, 0, width, height); //destination rectangle\n\n    return ctx.getImageData(0, 0, width, height);\n  }\n\n  async effect_blur_background(canvasElement, image, personSegmentation, config) {\n    /*canvasElement where to draw the results*/\n\n    /* config  = image--> imageData|HTMLimage|HTMLVideo, PersonSegmentation --> Prediction, edgeBlurAmount --> how many pixels to blur on the edge bettwen person and background, flipHorizontal --> flip image or not*/\n    const {\n      backgroundBlurAmount,\n      edgeBlurAmount,\n      flipHorizontal\n    } = config;\n    await bodyPix.drawBokehEffect(canvasElement, image, personSegmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n  }\n\n  async virtual_background(canvasElement, videoElement, personSegmentation, config) {\n    await this.virtualBackground_(personSegmentation, canvasElement, videoElement, config);\n  }\n\n  async blurBodyPart_(canvasElement, videoElement, personSegmentationParts, config) {\n    /*Reference of Body Parts*/\n    const parts = {\n      'left_face': 0,\n      'torso_front': 12,\n      'right_face': 1,\n      'torso_back': 13,\n      'left_upper_arm_front': 2,\n      'left_upper_leg_front': 14,\n      'left_upper_arm_back': 3,\n      'left_upper_leg_back': 15,\n      'right_upper_arm_front': 4,\n      'right_upper_leg_front': 16,\n      'right_upper_arm_back': 5,\n      'right_upper_leg_back': 17,\n      'left_lower_arm_front': 8,\n      'left_lower_leg_front': 18,\n      'left_lower_arm_back': 7,\n      'left_lower_leg_back': 19,\n      'right_lower_arm_front': 8,\n      'right_lower_leg_front': 20,\n      'right_lower_arm_back': 9,\n      'right_lower_leg_back': 21,\n      'left_hand': 10,\n      'left_foot': 22,\n      'right_hand': 11,\n      'right_foot': 23\n    };\n    const {\n      backgroundBlurAmount,\n      edgeBlurAmount,\n      flipHorizontal,\n      faceBodyPartIdsToBlur\n    } = config;\n    await bodyPix.blurBodyPart(canvasElement, videoElement, personSegmentationParts, faceBodyPartIdsToBlur, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n  }\n\n  async grayScale(canvasElement, videoElement, personSegmentation, config) {\n    const {\n      data: map\n    } = personSegmentation; // Extracting video data\n\n    const {\n      data: imgData\n    } = await this.videoImageData(960, 540, videoElement); //New canvas\n\n    const canvas = canvasElement;\n    /*Clean Canvas*/\n\n    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n    const newImg = canvas.getContext('2d').createImageData(canvas.width, canvas.height);\n    const newImgData = newImg.data; //[r0, g0, b0, a0, r1, g1, b1, a1, ..., rn, gn, bn, an]\n\n    for (let i = 0; i < map.length; i++) {\n      //sacamos los r g b del video en si \n      const [r, g, b, a] = [imgData[i * 4], imgData[i * 4 + 1], imgData[i * 4 + 2], imgData[i * 4 + 3]]; // GrayScale Effect\n\n      const gray = 0.3 * r + 0.59 * g + 0.11 * b;\n      [newImgData[i * 4], newImgData[i * 4 + 1], newImgData[i * 4 + 2], newImgData[i * 4 + 3]] = !map[i] ? [gray, gray, gray, 255] : [r, g, b, a];\n    }\n\n    canvas.getContext('2d').putImageData(newImg, 0, 0);\n    /*Paint the canvas*/\n  }\n\n  stopAnimationLoop() {\n    /*Working*/\n    this.stop = true;\n    return this.stop;\n  }\n\n  async loop_(type_prediciton, config) {\n    //effect_function, parameters_function\n    const prediction = await this.make_prediction_load();\n    const loaded_video = this.loaded_video;\n    const model_prediction = this.model_prediction;\n    /*Add canvas to HTML*/\n\n    VideoTracking.addVideo(document.querySelector('body'), this.canvasElement); // No es necesario anadir el HTML.... xd\n\n    const loopping = async () => {\n      /*Loop for animation*/\n      if (type_prediciton == 1) {\n        /*Blur Background - - PersonSegmentation*/\n\n        /*Opciones sacar datos de la imagen / mandar directamente el HTML tag*/\n        //const config = { flipHorizontal: this.flipHorizontal, internalResolution: this.internalResolution, segmentationThreshold: this.segmentationThreshold}\n        const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);\n        this.effect_blur_background(this.canvasElement, this.loaded_video, prediction_frame, config);\n      } else if (type_prediciton === 2) {\n        /*Virtual Background - PersonSegmentation*/\n        const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);\n        this.virtual_background(this.canvasElement, this.loaded_video, prediction_frame, config);\n      } else if (type_prediciton === 3) {\n        /*Gray SCale - PersonSegmentation*/\n        const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);\n        this.grayScale(this.canvasElement, this.loaded_video, prediction_frame, config);\n      } else if (type_prediciton === 4) {\n        /*Blur Body PARTS - PersonSegmentationPARTS*/\n        const prediction_frameParts = await model_prediction.segmentPersonParts(loaded_video, config);\n        this.blurBodyPart_(this.canvasElement, this.loaded_video, prediction_frameParts, config);\n      }\n      /*Cleaning canvas*/\n\n\n      if (this.stop) {\n        /*remove canvas If visible in the DOM*/\n        this.canvasElement.remove();\n        return;\n      }\n\n      window.requestAnimationFrame(loopping);\n    };\n\n    loopping();\n  }\n\n} //Testing New Classes\n//constructor(width, height, model_config, config_constrains, config_prediction )\n\n/*Dimensions of the input video width, height*/\n\n/* modelConfig = architecture: 'ResNet', 'mobileNetV1', outputStride: 8,16,32, multiplier: 1,0.75,0.50, quantBytes: 1,.75,.50 only mobile*/\n\n/* config_constrains = audio: audio_config, video: video_config*/\n\n/*config_prediction = flipHorizontal: true, internalResolution: 'high', segmentationThreshold: 0.7*/\n\n/*config_prediction (additional for MultiPerson) = maxDetections: 10,scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10*/\n\n/* Podemos definir 3 categorias Small, Medium, High Para la configuracion del Modelo*/\n\n\nconst model_config_ultra_low = {\n  architecture: \"MobileNetV1\",\n  outputStride: 16,\n  multiplier: 0.5,\n  quantBytes: 2\n}; //0\n\nconst model_config_low = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  multiplier: 0.75,\n  quantBytes: 2\n}; //1\n\nconst model_config_medium = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  multiplier: 0.75,\n  quantBytes: 2\n}; //2\n\nconst model_config_high = {\n  architecture: 'MobileNetV1',\n  outputStride: 8,\n  multiplier: 1,\n  quantBytes: 2\n}; //3\n\nconst model_config_ultra = {\n  architecture: 'ResNet50',\n  outputStride: 16,\n  quantBytes: 2\n}; //4\n\n/*Configuraciones De Las Prediciones*/\n\nconst effect_config_precission_low = {\n  flipHorizontal: false,\n  internalResolution: 'low',\n  segmentationThreshold: 0.7\n}; //0\n\nconst effect_config_precission_mid = {\n  flipHorizontal: false,\n  internalResolution: 'medium',\n  segmentationThreshold: 0.7\n}; //1\n\nconst effect_config_precission_high = {\n  flipHorizontal: false,\n  internalResolution: 'high',\n  segmentationThreshold: 0.7\n}; //2\n\nconst effect_config_precission_ultra = {\n  flipHorizontal: false,\n  internalResolution: 'ultra',\n  segmentationThreshold: 0.7\n}; //3\n\n/*Podemos Definir las dimensiones del video - ademas de cual camara pedir en moviles - dispositivo disponble en escritorio*/\n\n/*Types of Devices and camera Selected*/\n\nconst mobile_front_camera = {\n  audio: false,\n  video: {\n    facingMode: \"user\",\n    width: {\n      min: 640,\n      ideal: 1280,\n      max: 1920\n    },\n    height: {\n      min: 480,\n      ideal: 720,\n      max: 1080\n    }\n  }\n}; //0\n\nconst mobile_rear_camera = {\n  audio: false,\n  video: {\n    facingMode: {\n      exact: \"environment\"\n    },\n    width: {\n      min: 640,\n      ideal: 1280,\n      max: 1920\n    },\n    height: {\n      min: 480,\n      ideal: 720,\n      max: 1080\n    }\n  }\n}; //1\n\nconst desktop_selected_camera_device = {\n  audio: false,\n  video: {\n    deviceId: \"0faf4c1dc3b35ff09df6a31cfb747fd82b1666fb9c6c9e0a39c7dd83c9311157\",\n    width: {\n      min: 640,\n      ideal: 1280,\n      max: 1920\n    },\n    height: {\n      min: 480,\n      ideal: 720,\n      max: 1080\n    }\n  }\n}; //2\n\nconst desktop_select_camera_default = {\n  audio: false,\n  video: {\n    width: {\n      min: 640,\n      ideal: 1280,\n      max: 1920\n    },\n    height: {\n      min: 480,\n      ideal: 720,\n      max: 1080\n    }\n  }\n}; //3\n\n/*Configuracion del los Efectos*/\n\nconst config_effect_bokek = {\n  backgroundBlurAmount: 20,\n  edgeBlurAmount: 10\n};\nconst config_virtual_background = {\n  backgroundBlurAmount: 1,\n  edgeBlurAmount: 2.1,\n  URL: './js.jpg'\n};\nconst config_greyScale = {};\nconst config_blur_body_part = {\n  backgroundBlurAmount: 30,\n  edgeBlurAmount: 2.1,\n  faceBodyPartIdsToBlur: [0, 1]\n};\n/*Objecto Tracker*/\n//width, height, model_config_number, config_constrains, config_prediction\n\nconst type_model_architecture = 1;\nconst effect_config_type = 2;\nconst type_of_device = 3;\nconst camera_id_str = 'testing'; //When Passing type_of_device === 2\n\n/*las dimensiones que se piden el el mediaStream*/\n\nconst video_configs = {\n  audio: false,\n  video: {\n    width: 960,\n    height: 540\n  }\n};\nconst Tracking = new VideoTracking(type_model_architecture, effect_config_type, type_of_device); //Tracking.predictionModel.w\n\n/*Implementando 1...PersonSementation, Blur Background */\n//Tracking.predictionModel.loop_(1,  config_effect_bokek);\n//console.log(Tracking.predictionModel.stream_properties_mediaStream());\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n//const streamProperties = Tracking.predictionModel.stream_properties(test_stream);\n//console.log(streamProperties);\n//Implementado 2... VirtualBackground- PersonSegmenttion, \n//Tracking.predictionModel.loop_(2,  config_virtual_background);\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n//Implementado3  ... GrayScale Effect - Person Segmentation\n//Tracking.predictionModel.loop_(3, config_greyScale);\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n//Implementando4 ... Blur BodyParts - PersonSegmentationParts\n\nTracking.predictionModel.loop_(4, config_blur_body_part);\nconst canvas_stream = Tracking.predictionModel.canvas_mediStream();\nconsole.log(canvas_stream);\n/*Stop Anmation Loop*/\n//Tracking.predictionModel.stopAnimationLoop();","map":{"version":3,"sources":["/home/daviddlhz/integration/Front_End-Tribe/app_mokup/src/assets/js/Segmentation.js"],"names":["VideoTracking","constructor","model_config_number","config_prediction_number","type_device_number","device_id_str","model_architeture_options","architecture","outputStride","multiplier","quantBytes","effect_config_precission","flipHorizontal","internalResolution","segmentationThreshold","type_of_device","audio","video","facingMode","width","height","exact","deviceId","selection_model_option","selection_effect_option","selection_type_device","model","_load_model","videoStream","load_Video_stream","canvasElemenet","createCanvas","VideoElement","createVideo","predictionModel","Prediction","canvas","document","createElement","setAttribute","addVideo","HTMLelement","videoElement","appendChild","model_config","bodyPix","load","config_constrains","stream","navigator","mediaDevices","getUserMedia","getVideoTracks","getCapabilities","frameRate","srcObject","video_stream","PromiseCreator","style","display","Promise","resolve","reject","onloadedmetadata","videoWidth","videoHeight","loaded_model","videoMediaStream","stop","canvasElement","make_prediction_load","loaded_video","model_prediction","querySelector","stream_properties_mediaStream","canvas_mediStream","captureStream","test_video","visibility","canvas_stream","virtualBackground_","prediction","config","URL","newImg","getContext","createImageData","newImgData","data","map","pixelLength","length","videoData","videoImageData","imgData","getImageData","i","r","g","b","a","clearRect","backgroundBlurAmount","edgeBlurAmount","drawMask","context","img","drawImage","theData","ctx","Image","crossOrigin","onload","src","imageSmoothingEnabled","imageSmoothingQuality","effect_blur_background","image","personSegmentation","drawBokehEffect","virtual_background","blurBodyPart_","personSegmentationParts","parts","faceBodyPartIdsToBlur","blurBodyPart","grayScale","gray","putImageData","stopAnimationLoop","loop_","type_prediciton","loopping","prediction_frame","segmentPerson","prediction_frameParts","segmentPersonParts","remove","window","requestAnimationFrame","model_config_ultra_low","model_config_low","model_config_medium","model_config_high","model_config_ultra","effect_config_precission_low","effect_config_precission_mid","effect_config_precission_high","effect_config_precission_ultra","mobile_front_camera","min","ideal","max","mobile_rear_camera","desktop_selected_camera_device","desktop_select_camera_default","config_effect_bokek","config_virtual_background","config_greyScale","config_blur_body_part","type_model_architecture","effect_config_type","camera_id_str","video_configs","Tracking","console","log"],"mappings":"AAAA;AACA,MAAMA,aAAN,CAAoB;AAChBC,EAAAA,WAAW,CAACC,mBAAD,EAAsBC,wBAAtB,EAAgDC,kBAAhD,EAAoEC,aAAa,GAAG,MAApF,EAA4F;AAEnG,SAAKC,yBAAL,GAAiC,CAAC;AAACC,MAAAA,YAAY,EAAE,aAAf;AAA8BC,MAAAA,YAAY,EAAE,EAA5C;AAAgDC,MAAAA,UAAU,EAAE,GAA5D;AAAiEC,MAAAA,UAAU,EAAE;AAA7E,KAAD,EAC7B;AAAEH,MAAAA,YAAY,EAAE,aAAhB;AAA+BC,MAAAA,YAAY,EAAE,EAA7C;AAAiDC,MAAAA,UAAU,EAAE,IAA7D;AAAmEC,MAAAA,UAAU,EAAE;AAA/E,KAD6B,EAE7B;AAAEH,MAAAA,YAAY,EAAE,aAAhB;AAA+BC,MAAAA,YAAY,EAAE,EAA7C;AAAiDC,MAAAA,UAAU,EAAE,IAA7D;AAAmEC,MAAAA,UAAU,EAAE;AAA/E,KAF6B,EAG7B;AAAEH,MAAAA,YAAY,EAAE,aAAhB;AAA+BC,MAAAA,YAAY,EAAE,CAA7C;AAAgDC,MAAAA,UAAU,EAAE,CAA5D;AAA+DC,MAAAA,UAAU,EAAE;AAA3E,KAH6B,EAI7B;AAAEH,MAAAA,YAAY,EAAE,UAAhB;AAA4BC,MAAAA,YAAY,EAAE,EAA1C;AAA8CE,MAAAA,UAAU,EAAE;AAA1D,KAJ6B,CAAjC;AAMA,SAAKC,wBAAL,GAAgC,CAAC;AAAGC,MAAAA,cAAc,EAAE,KAAnB;AAA0BC,MAAAA,kBAAkB,EAAE,KAA9C;AAAqDC,MAAAA,qBAAqB,EAAE;AAA5E,KAAD,EAC5B;AAAGF,MAAAA,cAAc,EAAE,KAAnB;AAA0BC,MAAAA,kBAAkB,EAAE,QAA9C;AAAwDC,MAAAA,qBAAqB,EAAE;AAA/E,KAD4B,EAE5B;AAAGF,MAAAA,cAAc,EAAE,KAAnB;AAA0BC,MAAAA,kBAAkB,EAAE,MAA9C;AAAsDC,MAAAA,qBAAqB,EAAE;AAA7E,KAF4B,EAG5B;AAAGF,MAAAA,cAAc,EAAE,KAAnB;AAA0BC,MAAAA,kBAAkB,EAAE,OAA9C;AAAuDC,MAAAA,qBAAqB,EAAE;AAA9E,KAH4B,CAAhC;AAKA,SAAKC,cAAL,GAAsB,CAAE;AAAEC,MAAAA,KAAK,EAAE,KAAT;AAAgBC,MAAAA,KAAK,EAAE;AAAEC,QAAAA,UAAU,EAAE,MAAd;AAAsBC,QAAAA,KAAK,EAAE,GAA7B;AAAkCC,QAAAA,MAAM,EAAE;AAA1C;AAAvB,KAAF,EAClB;AAAEJ,MAAAA,KAAK,EAAE,KAAT;AAAgBC,MAAAA,KAAK,EAAE;AAAEC,QAAAA,UAAU,EAAE;AAAEG,UAAAA,KAAK,EAAE;AAAT,SAAd;AAAwCF,QAAAA,KAAK,EAAE,GAA/C;AAAoDC,QAAAA,MAAM,EAAE;AAA5D;AAAvB,KADkB,EAElB;AAAEJ,MAAAA,KAAK,EAAE,KAAT;AAAgBC,MAAAA,KAAK,EAAE;AAACK,QAAAA,QAAQ,EAAEjB,aAAX;AAA2Bc,QAAAA,KAAK,EAAE,GAAlC;AAAuCC,QAAAA,MAAM,EAAG;AAAhD;AAAvB,KAFkB,EAGlB;AAAEJ,MAAAA,KAAK,EAAE,KAAT;AAAgBC,MAAAA,KAAK,EAAE;AAAEE,QAAAA,KAAK,EAAG,GAAV;AAAeC,QAAAA,MAAM,EAAE;AAAvB;AAAvB,KAHkB,CAAtB;AAMA,SAAKG,sBAAL,GAA+B,KAAKjB,yBAAL,CAA+BJ,mBAA/B,CAA/B;AAEA,SAAKsB,uBAAL,GAA+B,KAAKb,wBAAL,CAA8BR,wBAA9B,CAA/B;AAEA,SAAKsB,qBAAL,GAA6B,KAAKV,cAAL,CAAoBX,kBAApB,CAA7B;AAEA,SAAKsB,KAAL,GAAa,KAAKC,WAAL,CAAiB,KAAKJ,sBAAtB,CAAb;AAA2D;;AAC3D,SAAKK,WAAL,GAAoB,KAAKC,iBAAL,CAAwB,KAAKJ,qBAA7B,CAApB;AAAwE;;AACxE,SAAKK,cAAL,GAAsB,KAAKC,YAAL,CAAkB,GAAlB,EAAuB,GAAvB,CAAtB;AACA,SAAKC,YAAL,GAAoB,KAAKC,WAAL,CAAiB,GAAjB,EAAsB,GAAtB,CAApB;AAAgD;AAKhD;;AAGA;;AACA,SAAKC,eAAL,GAAuB,IAAIC,UAAJ,CAAgB,KAAKT,KAArB,EAA4B,KAAKE,WAAjC,EAA8C,KAAKE,cAAnD,CAAvB;AACH;;AAEDC,EAAAA,YAAY,CAACZ,KAAD,EAAQC,MAAR,EAAe;AACvB,UAAMgB,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAf;AACAF,IAAAA,MAAM,CAACG,YAAP,CAAoB,OAApB,EAA6BpB,KAA7B;AACAiB,IAAAA,MAAM,CAACG,YAAP,CAAoB,QAApB,EAA8BnB,MAA9B;AACA,WAAOgB,MAAP;AACD;;AAGH,SAAOI,QAAP,CAAgBC,WAAhB,EAA6BC,YAA7B,EAA2C;AACvCD,IAAAA,WAAW,CAACE,WAAZ,CAAwBD,YAAxB;AACD;;AAEFf,EAAAA,WAAW,CAACiB,YAAD,EAAc;AACtB,WAAQC,OAAO,CAACC,IAAR,CAAaF,YAAb,CAAR;AACH;;AAID,QAAMf,iBAAN,CAAwBkB,iBAAxB,EAA0C;AAEtC,UAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoCJ,iBAApC,CAArB;AAA4E;;AAE5E,SAAKzB,QAAL,GAAgB0B,MAAM,CAACI,cAAP,GAAwB,CAAxB,EAA2BC,eAA3B,GAA6C/B,QAA7D;AACA,SAAKgC,SAAL,GAAiBN,MAAM,CAACI,cAAP,GAAwB,CAAxB,EAA2BC,eAA3B,GAA6CC,SAA9D;AACA,SAAKlC,MAAL,GAAc4B,MAAM,CAACI,cAAP,GAAwB,CAAxB,EAA2BC,eAA3B,GAA6CjC,MAA3D;AACA,SAAKD,KAAL,GAAa6B,MAAM,CAACI,cAAP,GAAwB,CAAxB,EAA2BC,eAA3B,GAA6ClC,KAA1D;AACA,SAAKa,YAAL,CAAkBuB,SAAlB,GAA8BP,MAA9B;AAAqC;;AAA2B;;AAChE,SAAKQ,YAAL,GAAoBR,MAApB;AAEA,WAAO,KAAKS,cAAL,EAAP;AACH;;AAMDxB,EAAAA,WAAW,CAACd,KAAD,EAAQC,MAAR,EAAe;AACtB;AACA,UAAMH,KAAK,GAAGoB,QAAQ,CAACC,aAAT,CAAuB,OAAvB,CAAd;AAEArB,IAAAA,KAAK,CAACsB,YAAN,CAAmB,UAAnB,EAA8B,OAA9B;AACAtB,IAAAA,KAAK,CAACsB,YAAN,CAAmB,OAAnB,EAA4BpB,KAA5B;AACAF,IAAAA,KAAK,CAACsB,YAAN,CAAmB,QAAnB,EAA6BnB,MAA7B,EANsB,CAOtB;AACA;AACA;;AACAH,IAAAA,KAAK,CAACyC,KAAN,CAAYC,OAAZ,GAAsB,MAAtB;AACA,WAAO1C,KAAP;AACH;;AAIDwC,EAAAA,cAAc,GAAK;AAAE;AACjB,WAAO,IAAIG,OAAJ,CAAY,CAACC,OAAD,EAAUC,MAAV,KAAqB;AACpC,WAAK9B,YAAL,CAAkB+B,gBAAlB,GAAqC,MAAM;AACvC,aAAK/B,YAAL,CAAkBb,KAAlB,GAA0B,KAAKa,YAAL,CAAkBgC,UAA5C;AACA,aAAKhC,YAAL,CAAkBZ,MAAlB,GAA2B,KAAKY,YAAL,CAAkBiC,WAA7C;AACJJ,QAAAA,OAAO,CAAC,KAAK7B,YAAN,CAAP;AACD,OAJC;AAKH,KANM,CAAP;AAOD;;AArGa,C,CA6GpB;;;AACA,MAAMG,UAAN,CAAiB;AACd;;AACA;;AACA;AACClC,EAAAA,WAAW,CAAEiE,YAAF,EAAgBC,gBAAhB,EAAkCrC,cAAlC,EAAiD;AAExD,SAAKoC,YAAL,GAAoBA,YAApB;AAAiC;;AACjC,SAAKC,gBAAL,GAAwBA,gBAAxB;AACA,SAAKC,IAAL,GAAY,KAAZ;AAAkB;;AAClB,SAAKC,aAAL,GAAqBvC,cAArB;AACH;;AAED,QAAMwC,oBAAN,GAA4B;AAAE;;AAC1B;;AAEA,QAAI,OAAO,KAAKC,YAAZ,KAA6B,WAAjC,EAA6C;AAAC;AAC1C,WAAKA,YAAL,GAAoB,MAAM,KAAKJ,gBAA/B;AACA,WAAKK,gBAAL,GAAwB,MAAM,KAAKN,YAAnC;AAAgD;;AAChD;;AACA,WAAK9C,MAAL,GAAc,KAAKmD,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkEjC,MAAhF;AACA,WAAKD,KAAL,GAAa,KAAKoD,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkElC,KAA/E;AAGAnB,MAAAA,aAAa,CAACwC,QAAd,CAAuBH,QAAQ,CAACoC,aAAT,CAAuB,MAAvB,CAAvB,EAAuD,KAAKF,YAA5D,EARyC,CAQkC;AAC9E;AACJ;;AAED,QAAMG,6BAAN,GAAqC;AACjC,UAAM,KAAKJ,oBAAL,EAAN;AAAkC;;AAClC,SAAKhD,QAAL,GAAgB,KAAKiD,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkE/B,QAAlF;AACA,SAAKgC,SAAL,GAAiB,KAAKiB,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkEC,SAAnF;AACA,SAAKlC,MAAL,GAAc,KAAKmD,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkEjC,MAAhF;AACA,SAAKD,KAAL,GAAa,KAAKoD,YAAL,CAAkBhB,SAAlB,CAA4BH,cAA5B,GAA6C,CAA7C,EAAgDC,eAAhD,GAAkElC,KAA/E;AAEA,WAAO,CAAC,KAAKG,QAAN,EAAgB,KAAKgC,SAArB,EAAgC,KAAKlC,MAArC,EAA6C,KAAKD,KAAlD,CAAP;AACH;;AAEDwD,EAAAA,iBAAiB,GAAE;AACf,UAAM3B,MAAM,GAAG,KAAKqB,aAAL,CAAmBO,aAAnB,CAAiC,EAAjC,CAAf;AAEA;;AACA,UAAMC,UAAU,GAAGxC,QAAQ,CAACoC,aAAT,CAAuB,UAAvB,CAAnB;AAGD;;AACCI,IAAAA,UAAU,CAACtC,YAAX,CAAwB,OAAxB,EAAiC,GAAjC;AACAsC,IAAAA,UAAU,CAACtC,YAAX,CAAwB,QAAxB,EAAkC,GAAlC;AACAsC,IAAAA,UAAU,CAACtC,YAAX,CAAwB,UAAxB,EAAoC,MAApC;;AAEAsC,IAAAA,UAAU,CAACd,gBAAX,GAA8B,MAAM;AAChCc,MAAAA,UAAU,CAAC1D,KAAX,GAAmB0D,UAAU,CAACb,UAA9B;AACAa,MAAAA,UAAU,CAACzD,MAAX,GAAoByD,UAAU,CAACZ,WAA/B;AACH,KAHD;;AAIAY,IAAAA,UAAU,CAACnB,KAAX,CAAiBoB,UAAjB,GAA8B,SAA9B;AACAD,IAAAA,UAAU,CAACtB,SAAX,GAAuBP,MAAvB;AACA,SAAK+B,aAAL,GAAqB/B,MAArB;AACA,WAAOA,MAAP;AAEH;;AAKD,QAAMgC,kBAAN,CAAyBC,UAAzB,EAAqCZ,aAArC,EAAoD3B,YAApD,EAAkEwC,MAAlE,EAAyE;AAErE,UAAM;AAACC,MAAAA;AAAD,QAAQD,MAAd,CAFqE,CAGrE;;AACA,UAAM9C,MAAM,GAAGiC,aAAf,CAJqE,CAIxC;;AAC7B,UAAMe,MAAM,GAAGhD,MAAM,CAACiD,UAAP,CAAkB,IAAlB,EAAwBC,eAAxB,CAAwC,GAAxC,EAA6C,GAA7C,CAAf,CALqE,CAKJ;;AACjE,UAAMC,UAAU,GAAGH,MAAM,CAACI,IAA1B,CANqE,CAQrE;;AACA,UAAM;AAACA,MAAAA,IAAI,EAACC;AAAN,QAAaR,UAAnB;AACA,UAAMS,WAAW,GAAGD,GAAG,CAACE,MAAxB,CAVqE,CAYrE;;AACA,UAAM;AAAEH,MAAAA,IAAI,EAAEI;AAAR,QAAsB,MAAM,KAAKC,cAAL,CAAoB,GAApB,EAAyB,GAAzB,EAA8BnD,YAA9B,CAAlC,CAbqE,CAerE;;AACA,UAAM;AAAC8C,MAAAA,IAAI,EAAEM;AAAP,QAAkB,MAAM,KAAKC,YAAL,CAAkB,GAAlB,EAAuB,GAAvB,EAA4BZ,GAA5B,CAA9B,CAhBqE,CAkBrE;;AACA,SAAK,IAAIa,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGN,WAApB,EAAiCM,CAAC,EAAlC,EAAsC;AAClC;AACA,YAAM,CAACC,CAAD,EAAIC,CAAJ,EAAOC,CAAP,EAAUC,CAAV,IAAe,CAACN,OAAO,CAACE,CAAC,GAAC,CAAH,CAAR,EAAeF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAM,CAAP,CAAtB,EAAiCF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAM,CAAP,CAAxC,EAAmDF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAM,CAAP,CAA1D,CAArB,CAFkC,CAIlC;;AACA,OACIT,UAAU,CAACS,CAAC,GAAC,CAAH,CADd,EAEIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAK,CAAN,CAFd,EAGIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAM,CAAP,CAHd,EAIIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAM,CAAP,CAJd,IAKI,CAACP,GAAG,CAACO,CAAD,CAAJ,GAAY,CAACC,CAAD,EAAIC,CAAJ,EAAOC,CAAP,EAAU,GAAV,CAAZ,GAA6B,CACDP,SAAS,CAACI,CAAC,GAAC,CAAH,CADR,EAEDJ,SAAS,CAACI,CAAC,GAAC,CAAF,GAAK,CAAN,CAFR,EAGDJ,SAAS,CAACI,CAAC,GAAC,CAAF,GAAM,CAAP,CAHR,EAID,CAJC,CALjC;AAUH;;AACD5D,IAAAA,MAAM,CAACiD,UAAP,CAAkB,IAAlB,EAAwBgB,SAAxB,CAAkC,CAAlC,EAAqC,CAArC,EAAwCjE,MAAM,CAACjB,KAA/C,EAAsDiB,MAAM,CAAChB,MAA7D;AACA,UAAM;AAAGkF,MAAAA,oBAAH;AAAyBC,MAAAA,cAAzB;AAAyC3F,MAAAA;AAAzC,QAA4DsE,MAAlE;AACArC,IAAAA,OAAO,CAAC2D,QAAR,CAAiBpE,MAAjB,EAAyBM,YAAzB,EAAuC0C,MAAvC,EAA+CkB,oBAA/C,EAAqEC,cAArE,EAAqF3F,cAArF;AACH;;AAKD,QAAMiF,cAAN,CAAsB1E,KAAtB,EAA6BC,MAA7B,EAAqCsB,YAArC,EAAkD;AAC9C;AAEA,UAAMN,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAf;AACAF,IAAAA,MAAM,CAACG,YAAP,CAAoB,OAApB,EAA6BpB,KAA7B;AACAiB,IAAAA,MAAM,CAACG,YAAP,CAAoB,QAApB,EAA8BnB,MAA9B;AAEA;;AACA,UAAMqF,OAAO,GAAGrE,MAAM,CAACiD,UAAP,CAAkB,IAAlB,CAAhB;AACA,UAAMqB,GAAG,GAAGhE,YAAZ;AAEA+D,IAAAA,OAAO,CAACE,SAAR,CAAkBD,GAAlB,EAAuB,CAAvB,EAA0B,CAA1B;AACA,QAAIE,OAAO,GAAGH,OAAO,CAACV,YAAR,CAAqB,CAArB,EAAwB,CAAxB,EAA2B5E,KAA3B,EAAkCC,MAAlC,CAAd;AACA,WAAOwF,OAAP;AACH;;AAGD,QAAMb,YAAN,CAAmB5E,KAAnB,EAA0BC,MAA1B,EAAkC+D,GAAlC,EAAsC;AAElC;AACA,UAAM/C,MAAM,GAAGC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAAf;AACA,UAAMuE,GAAG,GAAGzE,MAAM,CAACiD,UAAP,CAAkB,IAAlB,CAAZ;AAEAjD,IAAAA,MAAM,CAACjB,KAAP,GAAeA,KAAf;AACAiB,IAAAA,MAAM,CAAChB,MAAP,GAAgBA,MAAhB;AAEA;;AACA,UAAMsF,GAAG,GAAG,IAAII,KAAJ,EAAZ;AACAJ,IAAAA,GAAG,CAACK,WAAJ,GAAkB,EAAlB;AACA,UAAM,IAAInD,OAAJ,CAAYqC,CAAC,IAAIS,GAAG,CAACM,MAAJ,GAAWf,CAA5B,EAA+BS,GAAG,CAACO,GAAJ,GAAQ9B,GAAvC,CAAN,CAZkC,CAclC;;AACA0B,IAAAA,GAAG,CAACK,qBAAJ,GAA4B,IAA5B;AACAL,IAAAA,GAAG,CAACM,qBAAJ,GAA4B,MAA5B;AACAN,IAAAA,GAAG,CAACF,SAAJ,CAAcD,GAAd,EAAmB,CAAnB,EAAsB,CAAtB,EAAyBA,GAAG,CAACvF,KAA7B,EAAoCuF,GAAG,CAACtF,MAAxC,EAAgD;AAC5B,KADpB,EACsB,CADtB,EACyBD,KADzB,EACgCC,MADhC,EAjBkC,CAkBM;;AACxC,WAAOyF,GAAG,CAACd,YAAJ,CAAiB,CAAjB,EAAoB,CAApB,EAAuB5E,KAAvB,EAA8BC,MAA9B,CAAP;AACH;;AAED,QAAMgG,sBAAN,CAA6B/C,aAA7B,EAA4CgD,KAA5C,EAAmDC,kBAAnD,EAAwEpC,MAAxE,EAA+E;AAC3E;;AACA;AAEA,UAAM;AAACoB,MAAAA,oBAAD;AAAuBC,MAAAA,cAAvB;AAAuC3F,MAAAA;AAAvC,QAAyDsE,MAA/D;AACA,UAAMrC,OAAO,CAAC0E,eAAR,CAAwBlD,aAAxB,EAAuCgD,KAAvC,EAA8CC,kBAA9C,EAAkEhB,oBAAlE,EAAwFC,cAAxF,EAAwG3F,cAAxG,CAAN;AACH;;AAED,QAAM4G,kBAAN,CAAyBnD,aAAzB,EAAwC3B,YAAxC,EAAsD4E,kBAAtD,EAA2EpC,MAA3E,EAAkF;AAC9E,UAAM,KAAKF,kBAAL,CAAwBsC,kBAAxB,EAA4CjD,aAA5C,EAA2D3B,YAA3D,EAAyEwC,MAAzE,CAAN;AACH;;AAEA,QAAMuC,aAAN,CAAoBpD,aAApB,EAAmC3B,YAAnC,EAAiDgF,uBAAjD,EAA2ExC,MAA3E,EAAmF;AAEhF;AACA,UAAMyC,KAAK,GAAG;AACV,mBAAY,CADF;AAEV,qBAAe,EAFL;AAGV,oBAAa,CAHH;AAIV,oBAAa,EAJH;AAKV,8BAAuB,CALb;AAMV,8BAAuB,EANb;AAOV,6BAAsB,CAPZ;AAQV,6BAAsB,EARZ;AASV,+BAAyB,CATf;AAUV,+BAAwB,EAVd;AAWV,8BAAuB,CAXb;AAYV,8BAAuB,EAZb;AAaV,8BAAuB,CAbb;AAcV,8BAAuB,EAdb;AAeV,6BAAsB,CAfZ;AAgBV,6BAAsB,EAhBZ;AAiBV,+BAAwB,CAjBd;AAkBV,+BAAwB,EAlBd;AAmBV,8BAAuB,CAnBb;AAoBV,8BAAuB,EApBb;AAqBV,mBAAY,EArBF;AAsBV,mBAAa,EAtBH;AAuBV,oBAAa,EAvBH;AAwBV,oBAAc;AAxBJ,KAAd;AA2BA,UAAM;AAACrB,MAAAA,oBAAD;AAAuBC,MAAAA,cAAvB;AAAuC3F,MAAAA,cAAvC;AAAuDgH,MAAAA;AAAvD,QAAgF1C,MAAtF;AAEA,UAAMrC,OAAO,CAACgF,YAAR,CACFxD,aADE,EACa3B,YADb,EAC2BgF,uBAD3B,EACoDE,qBADpD,EAEFtB,oBAFE,EAEoBC,cAFpB,EAEoC3F,cAFpC,CAAN;AAGH;;AAED,QAAMkH,SAAN,CAAgBzD,aAAhB,EAA+B3B,YAA/B,EAA6C4E,kBAA7C,EAAiEpC,MAAjE,EAAwE;AAGpE,UAAM;AAACM,MAAAA,IAAI,EAACC;AAAN,QAAa6B,kBAAnB,CAHoE,CAKpE;;AACA,UAAM;AAAE9B,MAAAA,IAAI,EAACM;AAAP,QAAmB,MAAM,KAAKD,cAAL,CAAoB,GAApB,EAAyB,GAAzB,EAA8BnD,YAA9B,CAA/B,CANoE,CAQpE;;AACA,UAAMN,MAAM,GAAGiC,aAAf;AACA;;AACAjC,IAAAA,MAAM,CAACiD,UAAP,CAAkB,IAAlB,EAAwBgB,SAAxB,CAAkC,CAAlC,EAAqC,CAArC,EAAwCjE,MAAM,CAACjB,KAA/C,EAAsDiB,MAAM,CAAChB,MAA7D;AACA,UAAMgE,MAAM,GAAGhD,MAAM,CAACiD,UAAP,CAAkB,IAAlB,EAAwBC,eAAxB,CAAwClD,MAAM,CAACjB,KAA/C,EAAsDiB,MAAM,CAAChB,MAA7D,CAAf;AACA,UAAMmE,UAAU,GAAGH,MAAM,CAACI,IAA1B,CAboE,CAcpE;;AACA,SAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGP,GAAG,CAACE,MAAxB,EAAgCK,CAAC,EAAjC,EAAqC;AACjC;AACA,YAAM,CAACC,CAAD,EAAIC,CAAJ,EAAOC,CAAP,EAAUC,CAAV,IAAe,CAACN,OAAO,CAACE,CAAC,GAAC,CAAH,CAAR,EAAeF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAI,CAAL,CAAtB,EAA+BF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAI,CAAL,CAAtC,EAA+CF,OAAO,CAACE,CAAC,GAAC,CAAF,GAAI,CAAL,CAAtD,CAArB,CAFiC,CAIjC;;AACA,YAAM+B,IAAI,GAAK,MAAM9B,CAAP,GAAa,OAAOC,CAApB,GAA0B,OAAOC,CAA/C;AACA,OACIZ,UAAU,CAACS,CAAC,GAAC,CAAH,CADd,EAEIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAI,CAAL,CAFd,EAGIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAI,CAAL,CAHd,EAIIT,UAAU,CAACS,CAAC,GAAC,CAAF,GAAI,CAAL,CAJd,IAKI,CAACP,GAAG,CAACO,CAAD,CAAJ,GAAU,CAAC+B,IAAD,EAAOA,IAAP,EAAaA,IAAb,EAAmB,GAAnB,CAAV,GAAoC,CAAC9B,CAAD,EAAIC,CAAJ,EAAOC,CAAP,EAAUC,CAAV,CALxC;AAMH;;AACDhE,IAAAA,MAAM,CAACiD,UAAP,CAAkB,IAAlB,EAAwB2C,YAAxB,CAAqC5C,MAArC,EAA6C,CAA7C,EAAgD,CAAhD;AAAmD;AACtD;;AAED6C,EAAAA,iBAAiB,GAAE;AACf;AACA,SAAK7D,IAAL,GAAY,IAAZ;AACA,WAAO,KAAKA,IAAZ;AACH;;AAED,QAAM8D,KAAN,CAAYC,eAAZ,EAA6BjD,MAA7B,EAAoC;AAChC;AAEA,UAAMD,UAAU,GAAG,MAAM,KAAKX,oBAAL,EAAzB;AACA,UAAMC,YAAY,GAAG,KAAKA,YAA1B;AACA,UAAMC,gBAAgB,GAAG,KAAKA,gBAA9B;AAEA;;AACDxE,IAAAA,aAAa,CAACwC,QAAd,CAAuBH,QAAQ,CAACoC,aAAT,CAAuB,MAAvB,CAAvB,EAAuD,KAAKJ,aAA5D,EARiC,CAQ0C;;AAE1E,UAAM+D,QAAQ,GAAG,YAAW;AAAC;AAEzB,UAAID,eAAe,IAAI,CAAvB,EAAyB;AAAC;;AACtB;AACA;AACA,cAAME,gBAAgB,GAAG,MAAM7D,gBAAgB,CAAC8D,aAAjB,CAA+B/D,YAA/B,EAA6CW,MAA7C,CAA/B;AACA,aAAKkC,sBAAL,CAA4B,KAAK/C,aAAjC,EAAgD,KAAKE,YAArD,EAAmE8D,gBAAnE,EAAsFnD,MAAtF;AACH,OALD,MAOK,IAAIiD,eAAe,KAAK,CAAxB,EAA0B;AAAC;AAE5B,cAAME,gBAAgB,GAAG,MAAM7D,gBAAgB,CAAC8D,aAAjB,CAA+B/D,YAA/B,EAA6CW,MAA7C,CAA/B;AACA,aAAKsC,kBAAL,CAAwB,KAAKnD,aAA7B,EAA4C,KAAKE,YAAjD,EAA+D8D,gBAA/D,EAAkFnD,MAAlF;AAEH,OALI,MAOA,IAAGiD,eAAe,KAAK,CAAvB,EAAyB;AAAC;AAE3B,cAAME,gBAAgB,GAAG,MAAM7D,gBAAgB,CAAC8D,aAAjB,CAA+B/D,YAA/B,EAA6CW,MAA7C,CAA/B;AACA,aAAK4C,SAAL,CAAe,KAAKzD,aAApB,EAAmC,KAAKE,YAAxC,EAAsD8D,gBAAtD,EAAwEnD,MAAxE;AAEH,OALI,MAOA,IAAGiD,eAAe,KAAK,CAAvB,EAAyB;AAAC;AAC3B,cAAMI,qBAAqB,GAAG,MAAM/D,gBAAgB,CAACgE,kBAAjB,CAAoCjE,YAApC,EAAkDW,MAAlD,CAApC;AACA,aAAKuC,aAAL,CAAmB,KAAKpD,aAAxB,EAAuC,KAAKE,YAA5C,EAA0DgE,qBAA1D,EAAiFrD,MAAjF;AACH;AACD;;;AAGA,UAAG,KAAKd,IAAR,EAAa;AACT;AACA,aAAKC,aAAL,CAAmBoE,MAAnB;AACA;AACH;;AACDC,MAAAA,MAAM,CAACC,qBAAP,CAA6BP,QAA7B;AACJ,KApCA;;AAsCJA,IAAAA,QAAQ;AACP;;AAxRY,C,CA4RjB;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;AAEA;;;AACA,MAAMQ,sBAAsB,GAAG;AAACrI,EAAAA,YAAY,EAAE,aAAf;AAA8BC,EAAAA,YAAY,EAAE,EAA5C;AAAgDC,EAAAA,UAAU,EAAE,GAA5D;AAAiEC,EAAAA,UAAU,EAAE;AAA7E,CAA/B,C,CAA+G;;AAC/G,MAAMmI,gBAAgB,GAAG;AAAEtI,EAAAA,YAAY,EAAE,aAAhB;AAA+BC,EAAAA,YAAY,EAAE,EAA7C;AAAiDC,EAAAA,UAAU,EAAE,IAA7D;AAAmEC,EAAAA,UAAU,EAAE;AAA/E,CAAzB,C,CAA4G;;AAC5G,MAAMoI,mBAAmB,GAAG;AAAEvI,EAAAA,YAAY,EAAE,aAAhB;AAA+BC,EAAAA,YAAY,EAAE,EAA7C;AAAiDC,EAAAA,UAAU,EAAE,IAA7D;AAAmEC,EAAAA,UAAU,EAAE;AAA/E,CAA5B,C,CAA+G;;AAC/G,MAAMqI,iBAAiB,GAAG;AAAExI,EAAAA,YAAY,EAAE,aAAhB;AAA+BC,EAAAA,YAAY,EAAE,CAA7C;AAAgDC,EAAAA,UAAU,EAAE,CAA5D;AAA+DC,EAAAA,UAAU,EAAE;AAA3E,CAA1B,C,CAAyG;;AACzG,MAAMsI,kBAAkB,GAAG;AAAEzI,EAAAA,YAAY,EAAE,UAAhB;AAA4BC,EAAAA,YAAY,EAAE,EAA1C;AAA8CE,EAAAA,UAAU,EAAE;AAA1D,CAA3B,C,CAAyF;;AAGzF;;AACA,MAAMuI,4BAA4B,GAAG;AAAGrI,EAAAA,cAAc,EAAE,KAAnB;AAA0BC,EAAAA,kBAAkB,EAAE,KAA9C;AAAqDC,EAAAA,qBAAqB,EAAE;AAA5E,CAArC,C,CAAqH;;AACrH,MAAMoI,4BAA4B,GAAG;AAAGtI,EAAAA,cAAc,EAAE,KAAnB;AAA0BC,EAAAA,kBAAkB,EAAE,QAA9C;AAAwDC,EAAAA,qBAAqB,EAAE;AAA/E,CAArC,C,CAAwH;;AACxH,MAAMqI,6BAA6B,GAAG;AAAGvI,EAAAA,cAAc,EAAE,KAAnB;AAA0BC,EAAAA,kBAAkB,EAAE,MAA9C;AAAsDC,EAAAA,qBAAqB,EAAE;AAA7E,CAAtC,C,CAAuH;;AACvH,MAAMsI,8BAA8B,GAAG;AAAGxI,EAAAA,cAAc,EAAE,KAAnB;AAA0BC,EAAAA,kBAAkB,EAAE,OAA9C;AAAuDC,EAAAA,qBAAqB,EAAE;AAA9E,CAAvC,C,CAAyH;;AAGzH;;AACA;;AACA,MAAMuI,mBAAmB,GAAG;AAAErI,EAAAA,KAAK,EAAE,KAAT;AAAgBC,EAAAA,KAAK,EAAE;AAAEC,IAAAA,UAAU,EAAE,MAAd;AAAsBC,IAAAA,KAAK,EAAE;AAAEmI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,IAAnB;AAAyBC,MAAAA,GAAG,EAAE;AAA9B,KAA7B;AAAmEpI,IAAAA,MAAM,EAAE;AAAEkI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,GAAnB;AAAwBC,MAAAA,GAAG,EAAE;AAA7B;AAA3E;AAAvB,CAA5B,C,CAAqK;;AACrK,MAAMC,kBAAkB,GAAG;AAAEzI,EAAAA,KAAK,EAAE,KAAT;AAAgBC,EAAAA,KAAK,EAAE;AAAEC,IAAAA,UAAU,EAAE;AAAEG,MAAAA,KAAK,EAAE;AAAT,KAAd;AAAwCF,IAAAA,KAAK,EAAE;AAAEmI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,IAAnB;AAAyBC,MAAAA,GAAG,EAAE;AAA9B,KAA/C;AAAqFpI,IAAAA,MAAM,EAAE;AAAEkI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,GAAnB;AAAwBC,MAAAA,GAAG,EAAE;AAA7B;AAA7F;AAAvB,CAA3B,C,CAAsL;;AACtL,MAAME,8BAA8B,GAAI;AAAE1I,EAAAA,KAAK,EAAE,KAAT;AAAgBC,EAAAA,KAAK,EAAE;AAACK,IAAAA,QAAQ,EAAE,kEAAX;AAAgFH,IAAAA,KAAK,EAAE;AAAEmI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,IAAnB;AAAyBC,MAAAA,GAAG,EAAE;AAA9B,KAAvF;AAA6HpI,IAAAA,MAAM,EAAE;AAAEkI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,GAAnB;AAAwBC,MAAAA,GAAG,EAAE;AAA7B;AAArI;AAAvB,CAAxC,C,CAA2O;;AAC3O,MAAMG,6BAA6B,GAAG;AAAE3I,EAAAA,KAAK,EAAE,KAAT;AAAgBC,EAAAA,KAAK,EAAE;AAAEE,IAAAA,KAAK,EAAE;AAAEmI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,IAAnB;AAAyBC,MAAAA,GAAG,EAAE;AAA9B,KAAT;AAA+CpI,IAAAA,MAAM,EAAE;AAAEkI,MAAAA,GAAG,EAAE,GAAP;AAAYC,MAAAA,KAAK,EAAE,GAAnB;AAAwBC,MAAAA,GAAG,EAAE;AAA7B;AAAvD;AAAvB,CAAtC,C,CAA2J;;AAG3J;;AACA,MAAMI,mBAAmB,GAAG;AAACtD,EAAAA,oBAAoB,EAAE,EAAvB;AAA2BC,EAAAA,cAAc,EAAE;AAA3C,CAA5B;AACA,MAAMsD,yBAAyB,GAAG;AAACvD,EAAAA,oBAAoB,EAAE,CAAvB;AAA0BC,EAAAA,cAAc,EAAE,GAA1C;AAAgDpB,EAAAA,GAAG,EAAE;AAArD,CAAlC;AACA,MAAM2E,gBAAgB,GAAG,EAAzB;AACA,MAAMC,qBAAqB,GAAG;AAAEzD,EAAAA,oBAAoB,EAAE,EAAxB;AAA4BC,EAAAA,cAAc,EAAE,GAA5C;AAAiDqB,EAAAA,qBAAqB,EAAE,CAAC,CAAD,EAAI,CAAJ;AAAxE,CAA9B;AAGA;AACA;;AACA,MAAMoC,uBAAuB,GAAG,CAAhC;AACA,MAAMC,kBAAkB,GAAG,CAA3B;AACA,MAAMlJ,cAAc,GAAG,CAAvB;AACA,MAAMmJ,aAAa,GAAG,SAAtB,C,CAAgC;;AAGhC;;AACA,MAAMC,aAAa,GAAG;AAAEnJ,EAAAA,KAAK,EAAE,KAAT;AAAgBC,EAAAA,KAAK,EAAE;AAACE,IAAAA,KAAK,EAAE,GAAR;AAAaC,IAAAA,MAAM,EAAE;AAArB;AAAvB,CAAtB;AAGA,MAAMgJ,QAAQ,GAAG,IAAIpK,aAAJ,CAAkBgK,uBAAlB,EAA2CC,kBAA3C,EAA+DlJ,cAA/D,CAAjB,C,CAIA;;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAGA;;AACAqJ,QAAQ,CAAClI,eAAT,CAAyBgG,KAAzB,CAA+B,CAA/B,EAAkC6B,qBAAlC;AACA,MAAMhF,aAAa,GAAGqF,QAAQ,CAAClI,eAAT,CAAyByC,iBAAzB,EAAtB;AACA0F,OAAO,CAACC,GAAR,CAAYvF,aAAZ;AAGA;AACA","sourcesContent":["//Class Video_Tracking\nclass VideoTracking {\n    constructor(model_config_number, config_prediction_number, type_device_number, device_id_str = 'null' ){\n\n        this.model_architeture_options = [{architecture: \"MobileNetV1\", outputStride: 16, multiplier: 0.5, quantBytes: 2,},\n            { architecture: 'MobileNetV1', outputStride: 16, multiplier: 0.75, quantBytes: 2},\n            { architecture: 'MobileNetV1', outputStride: 16, multiplier: 0.75, quantBytes: 2}, \n            { architecture: 'MobileNetV1', outputStride: 8, multiplier: 1, quantBytes: 2},\n            { architecture: 'ResNet50', outputStride: 16, quantBytes: 2}];\n        \n        this.effect_config_precission = [{  flipHorizontal: false, internalResolution: 'low', segmentationThreshold: 0.7},\n            {  flipHorizontal: false, internalResolution: 'medium', segmentationThreshold: 0.7},\n            {  flipHorizontal: false, internalResolution: 'high', segmentationThreshold: 0.7},\n            {  flipHorizontal: false, internalResolution: 'ultra', segmentationThreshold: 0.7}];\n        \n        this.type_of_device = [ { audio: false, video: { facingMode: \"user\", width: 960, height: 540 }},\n            { audio: false, video: { facingMode: { exact: \"environment\" }, width: 960, height: 540 }},\n            { audio: false, video: {deviceId: device_id_str,  width: 960, height:  540 }},\n            { audio: false, video: { width:  960, height: 540 }}];\n\n\n        this.selection_model_option =  this.model_architeture_options[model_config_number];\n\n        this.selection_effect_option = this.effect_config_precission[config_prediction_number];\n        \n        this.selection_type_device = this.type_of_device[type_device_number];\n        \n        this.model = this._load_model(this.selection_model_option);/*Promise Containtng Model*/\n        this.videoStream =  this.load_Video_stream( this.selection_type_device);/*Promise Containing Video MediaStream*/\n        this.canvasElemenet = this.createCanvas(960, 540);\n        this.VideoElement = this.createVideo(960, 540); /*Video Element*/\n\n\n\n     \n        //this.canvasElement = this.createCanvas(this.width, this.height);/*Create canvas to Write to setting some dimensions*/\n\n\n        /*podemos usar esto*/\n        this.predictionModel = new Prediction (this.model, this.videoStream, this.canvasElemenet);\n    }\n\n    createCanvas(width, height){\n        const canvas = document.createElement('canvas');\n        canvas.setAttribute('width', width);\n        canvas.setAttribute('height', height);\n        return canvas\n      }\n\n    \n    static addVideo(HTMLelement, videoElement) {\n        HTMLelement.appendChild(videoElement);\n      }\n    \n     _load_model(model_config){\n        return  bodyPix.load(model_config);\n    }\n\n\n\n    async load_Video_stream(config_constrains){\n     \n        const stream = await navigator.mediaDevices.getUserMedia(config_constrains);/*MediaStream Video*/\n\n        this.deviceId = stream.getVideoTracks()[0].getCapabilities().deviceId;\n        this.frameRate = stream.getVideoTracks()[0].getCapabilities().frameRate;\n        this.height = stream.getVideoTracks()[0].getCapabilities().height;\n        this.width = stream.getVideoTracks()[0].getCapabilities().width;\n        this.VideoElement.srcObject = stream;/*SetVideo Stream Source*/ /*MediaStream Video*/\n        this.video_stream = stream;\n\n        return this.PromiseCreator();\n    }\n\n\n\n\n    \n    createVideo(width, height){\n        /*Create Video de donde sacaramos la informacion para hacer la prediccion y posteriormente dibujar el canvas*/\n        const video = document.createElement('video');\n\n        video.setAttribute('autoplay','false');\n        video.setAttribute('width', width);\n        video.setAttribute('height', height);\n        //video.setAttribute('playsinline', 'false');\n        //video.setAttribute('controls', 'false');\n        //video.style.visibility = 'visible';\n        video.style.display = 'none';\n        return video;\n    }\n\n\n    \n    PromiseCreator ()  { /* Return Promise VideoElement when all data is loaded and ready  with certains dimensions*/\n        return new Promise((resolve, reject) => {\n            this.VideoElement.onloadedmetadata = () => {\n                this.VideoElement.width = this.VideoElement.videoWidth;\n                this.VideoElement.height = this.VideoElement.videoHeight;\n            resolve(this.VideoElement);\n          };\n        });\n      }\n\n\n}\n\n\n\n\n//Class Prediction\nclass Prediction {\n   /*config = flipHorizontal: true, internalResolution: 'high', segmentationThreshold: 0.7*/\n   /*config (additional for MultiPerson) = maxDetections: 10,scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10*/\n   /* type_prediciton = String 'Person', 'MultiPerson'*/ \n    constructor( loaded_model, videoMediaStream, canvasElemenet){\n\n        this.loaded_model = loaded_model;/*Promise of Model*/\n        this.videoMediaStream = videoMediaStream;\n        this.stop = false;/*Stop Animation Loop*/\n        this.canvasElement = canvasElemenet;\n    }\n\n    async make_prediction_load(){ /* Returns unit8Campled for every pixel in the Ho*Wo Element array 0: Backgrounnd : 1:Person*/\n        /*type_prediciton 1 --> Person, 2 --> MultiPerson, 3 --> BodyParts Prediciton/\n        /*HTMLVideoElement --> ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement*/\n        if (typeof this.loaded_video === 'undefined'){/* Load one time video MediaStream if was not loaded yet*/\n            this.loaded_video = await this.videoMediaStream;\n            this.model_prediction = await this.loaded_model;/*cargando el model*/\n            /*add video to HTML*/\n            this.height = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().height;\n            this.width = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().width;\n\n            \n            VideoTracking.addVideo(document.querySelector('body'), this.loaded_video );// No es necesario anadir el HTML.... xd\n        }\n    }\n\n    async stream_properties_mediaStream(){\n        await this.make_prediction_load();/*if video is no loaded yet*/\n        this.deviceId = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().deviceId;\n        this.frameRate = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().frameRate;\n        this.height = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().height;\n        this.width = this.loaded_video.srcObject.getVideoTracks()[0].getCapabilities().width;\n\n        return [this.deviceId, this.frameRate, this.height, this.width ];    \n    }\n    \n    canvas_mediStream(){\n        const stream = this.canvasElement.captureStream(24);\n\n        /*Adding stream to video for testing*/\n        const test_video = document.querySelector('#testing');\n       \n       \n       /*testing canvas_mediStream*/\n        test_video.setAttribute('width', 960);\n        test_video.setAttribute('height', 540);\n        test_video.setAttribute('autoplay', 'true');\n        \n        test_video.onloadedmetadata = () => {\n            test_video.width = test_video.videoWidth;\n            test_video.height = test_video.videoHeight;\n        };\n        test_video.style.visibility = 'visible';\n        test_video.srcObject = stream;\n        this.canvas_stream = stream;\n        return stream;\n\n    }\n\n\n\n    \n    async virtualBackground_(prediction, canvasElement, videoElement, config){\n \n        const {URL} = config;\n        //new canvas\n        const canvas = canvasElement;//cremaos un blank array para llenarlo\n        const newImg = canvas.getContext('2d').createImageData(960, 540);//create blank new ImageData\n        const newImgData = newImg.data;\n\n        //prediction\n        const {data:map} = prediction;\n        const pixelLength = map.length;\n        \n        //Video Data\n        const { data: videoData } = await this.videoImageData(960, 540, videoElement);\n    \n        //imageData\n        const {data: imgData} = await this.getImageData(960, 540, URL);\n\n        //es los pixels de no persona dibujar La imagen en si\n        for (let i = 0; i < pixelLength; i++) {\n            //los pixels de la imagen si es no es persona\n            const [r, g, b, a] = [imgData[i*4], imgData[i*4 + 1], imgData[i*4 + 2], imgData[i*4 + 3]];\n\n            //revisamos que sea 1 persona , 0 otra cosa\n            [\n                newImgData[i*4], \n                newImgData[i*4 +1],\n                newImgData[i*4 + 2], \n                newImgData[i*4 + 3]\n            ] = !map[i]   ? [r, g, b, 255] : [\n                                            videoData[i*4], \n                                            videoData[i*4 +1], \n                                            videoData[i*4 + 2], \n                                            0]\n        }\n        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n        const {  backgroundBlurAmount, edgeBlurAmount, flipHorizontal } = config;\n        bodyPix.drawMask(canvas, videoElement, newImg, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);    \n    }\n\n\n\n\n    async videoImageData (width, height, videoElement){\n        /*Create Canvas*/\n        \n        const canvas = document.createElement('canvas');\n        canvas.setAttribute('width', width);\n        canvas.setAttribute('height', height);\n        \n        /*Write data To image*/\n        const context = canvas.getContext('2d');\n        const img = videoElement;\n        \n        context.drawImage(img, 0, 0 );\n        var theData = context.getImageData(0, 0, width, height);\n        return theData;\n    }\n\n\n    async getImageData(width, height, URL){\n        \n        //create Image object\n        const canvas = document.createElement('canvas');\n        const ctx = canvas.getContext('2d');\n\n        canvas.width = width;\n        canvas.height = height;\n\n        /*create new image*/\n        const img = new Image();\n        img.crossOrigin = '';\n        await new Promise(r => img.onload=r, img.src=URL);\n        \n        //resize image to canvas\n        ctx.imageSmoothingEnabled = true;\n        ctx.imageSmoothingQuality = 'high';\n        ctx.drawImage(img, 0, 0, img.width, img.height, //source rectangle\n                            0,0, width, height);//destination rectangle\n        return ctx.getImageData(0, 0, width, height);   \n    }\n\n    async effect_blur_background(canvasElement, image, personSegmentation,  config){\n        /*canvasElement where to draw the results*/\n        /* config  = image--> imageData|HTMLimage|HTMLVideo, PersonSegmentation --> Prediction, edgeBlurAmount --> how many pixels to blur on the edge bettwen person and background, flipHorizontal --> flip image or not*/\n\n        const {backgroundBlurAmount, edgeBlurAmount, flipHorizontal} = config; \n        await bodyPix.drawBokehEffect(canvasElement, image, personSegmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n    }\n\n    async virtual_background(canvasElement, videoElement, personSegmentation,  config){\n        await this.virtualBackground_(personSegmentation, canvasElement, videoElement, config);\n    }\n\n     async blurBodyPart_(canvasElement, videoElement, personSegmentationParts,  config) {\n\n        /*Reference of Body Parts*/\n        const parts = {\n            'left_face':0, \t\n            'torso_front': 12,\n            'right_face':1,\n            'torso_back':13,\n            'left_upper_arm_front':2,\n            'left_upper_leg_front':14,\n            'left_upper_arm_back':3,\n            'left_upper_leg_back':15,\n            'right_upper_arm_front': 4,\n            'right_upper_leg_front':16,\n            'right_upper_arm_back':5,\n            'right_upper_leg_back':17,\n            'left_lower_arm_front':8,\n            'left_lower_leg_front':18,\n            'left_lower_arm_back':7,\n            'left_lower_leg_back':19,\n            'right_lower_arm_front':8,\n            'right_lower_leg_front':20,\n            'right_lower_arm_back':9,\n            'right_lower_leg_back':21,\n            'left_hand':10,\n            'left_foot': 22,\n            'right_hand':11,\n            'right_foot': 23\n        }\n    \n        const {backgroundBlurAmount, edgeBlurAmount, flipHorizontal, faceBodyPartIdsToBlur} = config;\n\n        await bodyPix.blurBodyPart(\n            canvasElement, videoElement, personSegmentationParts, faceBodyPartIdsToBlur,\n            backgroundBlurAmount, edgeBlurAmount, flipHorizontal);\n    }\n     \n    async grayScale(canvasElement, videoElement, personSegmentation, config){\n        \n      \n        const {data:map} = personSegmentation;\n        \n        // Extracting video data\n        const { data:imgData } = await this.videoImageData(960, 540, videoElement);\n\n        //New canvas\n        const canvas = canvasElement;\n        /*Clean Canvas*/\n        canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n        const newImg = canvas.getContext('2d').createImageData(canvas.width, canvas.height);\n        const newImgData = newImg.data;\n        //[r0, g0, b0, a0, r1, g1, b1, a1, ..., rn, gn, bn, an]\n        for (let i = 0; i < map.length; i++) {\n            //sacamos los r g b del video en si \n            const [r, g, b, a] = [imgData[i*4], imgData[i*4+1], imgData[i*4+2], imgData[i*4+3]];\n            \n            // GrayScale Effect\n            const gray = ((0.3 * r) + (0.59 * g) + (0.11 * b));\n            [\n                newImgData[i*4],\n                newImgData[i*4+1],\n                newImgData[i*4+2],\n                newImgData[i*4+3]\n            ] = !map[i] ? [gray, gray, gray, 255] : [r, g, b, a];\n        }\n        canvas.getContext('2d').putImageData(newImg, 0, 0);/*Paint the canvas*/\n    }\n\n    stopAnimationLoop(){\n        /*Working*/\n        this.stop = true;\n        return this.stop;\n    }\n\n    async loop_(type_prediciton, config){\n        //effect_function, parameters_function\n \n        const prediction = await this.make_prediction_load();\n        const loaded_video = this.loaded_video;\n        const model_prediction = this.model_prediction;\n        \n        /*Add canvas to HTML*/\n       VideoTracking.addVideo(document.querySelector('body'), this.canvasElement);// No es necesario anadir el HTML.... xd\n\n        const loopping = async () =>{/*Loop for animation*/\n           \n            if (type_prediciton == 1){/*Blur Background - - PersonSegmentation*/\n                /*Opciones sacar datos de la imagen / mandar directamente el HTML tag*/\n                //const config = { flipHorizontal: this.flipHorizontal, internalResolution: this.internalResolution, segmentationThreshold: this.segmentationThreshold}\n                const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);\n                this.effect_blur_background(this.canvasElement, this.loaded_video, prediction_frame,  config);\n            }\n\n            else if (type_prediciton === 2){/*Virtual Background - PersonSegmentation*/\n                \n                const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);     \n                this.virtual_background(this.canvasElement, this.loaded_video, prediction_frame,  config);\n    \n            }\n\n            else if(type_prediciton === 3){/*Gray SCale - PersonSegmentation*/\n                \n                const prediction_frame = await model_prediction.segmentPerson(loaded_video, config);     \n                this.grayScale(this.canvasElement, this.loaded_video, prediction_frame, config);\n              \n            }\n\n            else if(type_prediciton === 4){/*Blur Body PARTS - PersonSegmentationPARTS*/\n                const prediction_frameParts = await model_prediction.segmentPersonParts(loaded_video, config); \n                this.blurBodyPart_(this.canvasElement, this.loaded_video, prediction_frameParts, config);\n            }\n            /*Cleaning canvas*/\n            \n\n            if(this.stop){\n                /*remove canvas If visible in the DOM*/\n                this.canvasElement.remove();\n                return;\n            }\n            window.requestAnimationFrame(loopping);\n       }\n\n    loopping();\n    }\n\n}\n\n//Testing New Classes\n//constructor(width, height, model_config, config_constrains, config_prediction )\n/*Dimensions of the input video width, height*/\n/* modelConfig = architecture: 'ResNet', 'mobileNetV1', outputStride: 8,16,32, multiplier: 1,0.75,0.50, quantBytes: 1,.75,.50 only mobile*/\n/* config_constrains = audio: audio_config, video: video_config*/\n/*config_prediction = flipHorizontal: true, internalResolution: 'high', segmentationThreshold: 0.7*/\n/*config_prediction (additional for MultiPerson) = maxDetections: 10,scoreThreshold: 0.2, nmsRadius: 20, minKeypointScore: 0.3, refineSteps: 10*/\n\n/* Podemos definir 3 categorias Small, Medium, High Para la configuracion del Modelo*/\nconst model_config_ultra_low = {architecture: \"MobileNetV1\", outputStride: 16, multiplier: 0.5, quantBytes: 2,}//0\nconst model_config_low = { architecture: 'MobileNetV1', outputStride: 16, multiplier: 0.75, quantBytes: 2}; //1\nconst model_config_medium = { architecture: 'MobileNetV1', outputStride: 16, multiplier: 0.75, quantBytes: 2}; //2\nconst model_config_high = { architecture: 'MobileNetV1', outputStride: 8, multiplier: 1, quantBytes: 2}; //3\nconst model_config_ultra = { architecture: 'ResNet50', outputStride: 16, quantBytes: 2}; //4\n\n\n/*Configuraciones De Las Prediciones*/\nconst effect_config_precission_low = {  flipHorizontal: false, internalResolution: 'low', segmentationThreshold: 0.7}//0\nconst effect_config_precission_mid = {  flipHorizontal: false, internalResolution: 'medium', segmentationThreshold: 0.7}//1\nconst effect_config_precission_high = {  flipHorizontal: false, internalResolution: 'high', segmentationThreshold: 0.7}//2\nconst effect_config_precission_ultra = {  flipHorizontal: false, internalResolution: 'ultra', segmentationThreshold: 0.7}//3\n\n\n/*Podemos Definir las dimensiones del video - ademas de cual camara pedir en moviles - dispositivo disponble en escritorio*/\n/*Types of Devices and camera Selected*/\nconst mobile_front_camera = { audio: false, video: { facingMode: \"user\", width: { min: 640, ideal: 1280, max: 1920 }, height: { min: 480, ideal: 720, max: 1080 } }};//0\nconst mobile_rear_camera = { audio: false, video: { facingMode: { exact: \"environment\" }, width: { min: 640, ideal: 1280, max: 1920 }, height: { min: 480, ideal: 720, max: 1080 } }};//1\nconst desktop_selected_camera_device =  { audio: false, video: {deviceId: \"0faf4c1dc3b35ff09df6a31cfb747fd82b1666fb9c6c9e0a39c7dd83c9311157\" , width: { min: 640, ideal: 1280, max: 1920 }, height: { min: 480, ideal: 720, max: 1080 } }};//2\nconst desktop_select_camera_default = { audio: false, video: { width: { min: 640, ideal: 1280, max: 1920 }, height: { min: 480, ideal: 720, max: 1080 } }};//3\n\n\n/*Configuracion del los Efectos*/\nconst config_effect_bokek = {backgroundBlurAmount: 20, edgeBlurAmount: 10};\nconst config_virtual_background = {backgroundBlurAmount: 1, edgeBlurAmount: 2.1,  URL: './js.jpg'};\nconst config_greyScale = {};\nconst config_blur_body_part = { backgroundBlurAmount: 30, edgeBlurAmount: 2.1, faceBodyPartIdsToBlur: [0, 1] };\n\n\n/*Objecto Tracker*/\n//width, height, model_config_number, config_constrains, config_prediction\nconst type_model_architecture = 1;\nconst effect_config_type = 2;\nconst type_of_device = 3;\nconst camera_id_str = 'testing';//When Passing type_of_device === 2\n\n\n/*las dimensiones que se piden el el mediaStream*/\nconst video_configs = { audio: false, video: {width: 960, height: 540}}\n\n\nconst Tracking = new VideoTracking(type_model_architecture, effect_config_type, type_of_device);\n\n\n\n//Tracking.predictionModel.w\n/*Implementando 1...PersonSementation, Blur Background */\n\n//Tracking.predictionModel.loop_(1,  config_effect_bokek);\n//console.log(Tracking.predictionModel.stream_properties_mediaStream());\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n//const streamProperties = Tracking.predictionModel.stream_properties(test_stream);\n//console.log(streamProperties);\n\n//Implementado 2... VirtualBackground- PersonSegmenttion, \n//Tracking.predictionModel.loop_(2,  config_virtual_background);\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n\n//Implementado3  ... GrayScale Effect - Person Segmentation\n//Tracking.predictionModel.loop_(3, config_greyScale);\n//const canvas_stream = Tracking.predictionModel.canvas_mediStream();\n//console.log(canvas_stream);\n\n\n//Implementando4 ... Blur BodyParts - PersonSegmentationParts\nTracking.predictionModel.loop_(4, config_blur_body_part);\nconst canvas_stream = Tracking.predictionModel.canvas_mediStream();\nconsole.log(canvas_stream);\n\n\n/*Stop Anmation Loop*/\n//Tracking.predictionModel.stopAnimationLoop();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"]},"metadata":{},"sourceType":"module"}